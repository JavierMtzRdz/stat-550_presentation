@misc{8Sex:2024,
  title = {882: {{Significant}} - Explain Xkcd},
  urldate = {2024-03-19},
  howpublished = {https://www.explainxkcd.com/wiki/index.php/882:\_Significant},
  file = {/Users/javiermtz/Zotero/storage/TGH8YZJT/882_Significant.html}
}

@article{AltmanBland:1995,
  title = {Statistics Notes: {{Absence}} of Evidence Is Not Evidence of Absence},
  shorttitle = {Statistics Notes},
  author = {Altman, Douglas G. and Bland, J. Martin},
  year = {1995},
  month = aug,
  journal = {BMJ},
  volume = {311},
  number = {7003},
  pages = {485},
  publisher = {British Medical Journal Publishing Group},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.311.7003.485},
  urldate = {2024-03-19},
  abstract = {The non-equivalence of statistical significance and clinical importance has long been recognised, but this error of interpretation remains common. Although a significant result in a large study may sometimes not be clinically important, a far greater problem arises from misinterpretation of non-significant findings. By convention a P value greater than 5\% (P{$>$}0.05) is called ``not significant.'' Randomised controlled clinical trials that do not show a significant difference between the treatments being compared are often called ``negative.'' This term wrongly implies that the study has shown that there is no difference, whereas usually all that has been shown is an absence of evidence of a difference. These are quite different statements. The sample size of controlled trials is generally inadequate, with a consequent lack of power to detect real, and clinically worthwhile, differences in treatment. Freiman et al1 found that only {\dots}},
  chapter = {Paper},
  copyright = {{\copyright} 1995 BMJ Publishing Group Ltd.},
  langid = {english},
  pmid = {7647644}
}

@article{AmrheinGreenlandMcShane:2019,
  title = {Scientists Rise up against Statistical Significance},
  author = {Amrhein, Valentin and Greenland, Sander and McShane, Blake},
  year = {2019},
  month = mar,
  journal = {Nature},
  volume = {567},
  number = {7748},
  pages = {305--307},
  publisher = {Nature Publishing Group},
  doi = {10.1038/d41586-019-00857-9},
  urldate = {2024-03-19},
  abstract = {Valentin Amrhein, Sander Greenland, Blake McShane and more than 800 signatories call for an end to hyped claims and the dismissal of possibly crucial effects.},
  copyright = {2021 Nature},
  langid = {english},
  keywords = {Research data,Research management},
  annotation = {Bandiera\_abtest: a Cg\_type: Comment Subject\_term: Research data, Research management},
  file = {/Users/javiermtz/Zotero/storage/R4JPLI66/d41586-019-00857-9.html}
}

@misc{Aschwanden:2016,
  title = {You {{Can}}'t {{Trust What You Read About Nutrition}}},
  author = {Aschwanden, Christie},
  year = {2016},
  month = jan,
  journal = {FiveThirtyEight},
  urldate = {2024-03-19},
  abstract = {Photographs by Anna Maria Barry-Jester As the new year begins, millions of people are vowing to shape up their eating habits. This usually involves dividing foo{\dots}},
  langid = {american},
  file = {/Users/javiermtz/Zotero/storage/WKXY3Y92/you-cant-trust-what-you-read-about-nutrition.html}
}

@article{Baker:2016,
  title = {Statisticians Issue Warning over Misuse of {{P}} Values},
  author = {Baker, Monya},
  year = {2016},
  month = mar,
  journal = {Nature},
  volume = {531},
  number = {7593},
  pages = {151--151},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature.2016.19503},
  urldate = {2024-03-19},
  abstract = {Policy statement aims to halt missteps in the quest for certainty.},
  copyright = {2016 Springer Nature Limited},
  langid = {english},
  keywords = {Peer review,Policy,Publishing,Research data}
}

@article{BrodeurCookHeyes:2020,
  title = {Methods {{Matter}}: P-{{Hacking}} and {{Publication Bias}} in {{Causal Analysis}} in {{Economics}}},
  shorttitle = {Methods {{Matter}}},
  author = {Brodeur, Abel and Cook, Nikolai and Heyes, Anthony},
  year = {2020},
  month = nov,
  journal = {American Economic Review},
  volume = {110},
  number = {11},
  pages = {3634--3660},
  issn = {0002-8282},
  doi = {10.1257/aer.20190687},
  urldate = {2024-03-19},
  abstract = {The credibility revolution in economics has promoted causal identification using randomized control trials (RCT), difference-in-differences (DID), instrumental variables (IV) and regression discontinuity design (RDD). Applying multiple approaches to over 21,000 hypothesis tests published in 25 leading economics journals, we find that the extent of p-hacking and publication bias varies greatly by method. IV (and to a lesser extent DID) are particularly problematic. We find no evidence that (i) papers published in the Top 5 journals are different to others; (ii) the journal "revise and resubmit" process mitigates the problem; (iii) things are improving through time.},
  langid = {english},
  keywords = {and Selection,Hypothesis Testing: General,Model Evaluation,Sociology of Economics,Validation}
}

@article{Colquhoun:2014,
  title = {An Investigation of the False Discovery Rate and the Misinterpretation of P-Values},
  author = {Colquhoun, David},
  year = {2014},
  month = nov,
  journal = {Royal Society Open Science},
  volume = {1},
  number = {3},
  pages = {140216},
  publisher = {Royal Society},
  doi = {10.1098/rsos.140216},
  urldate = {2024-03-19},
  abstract = {If you use p=0.05 to suggest that you have made a discovery, you will be wrong at least 30\% of the time. If, as is often the case, experiments are underpowered, you will be wrong most of the time. This conclusion is demonstrated from several points of view. First, tree diagrams which show the close analogy with the screening test problem. Similar conclusions are drawn by repeated simulations of t-tests. These mimic what is done in real life, which makes the results more persuasive. The simulation method is used also to evaluate the extent to which effect sizes are over-estimated, especially in underpowered experiments. A script is supplied to allow the reader to do simulations themselves, with numbers appropriate for their own work. It is concluded that if you wish to keep your false discovery rate below 5\%, you need to use a three-sigma rule, or to insist on p{$\leq$}0.001. And never use the word `significant'.},
  keywords = {false discovery rate,reproducibility,significance tests,statistics}
}

@misc{Harrell:2017,
  title = {A {{Litany}} of {{Problems With}} P-Values},
  author = {Harrell, Frank},
  year = {2017},
  month = feb,
  journal = {Statistical Thinking},
  urldate = {2024-03-19},
  abstract = {p-values are very often misinterpreted. p-values and null hypothesis significant testing have hurt science. This article attempts to catalog all the ways in which these happen.},
  howpublished = {https://www.fharrell.com/post/pval-litany/},
  langid = {english},
  file = {/Users/javiermtz/Zotero/storage/2XG9ZRPI/pval-litany.html}
}

@misc{iRF1:1913,
  title = {An Image of {{Ronald Fisher}} in 1913},
  shorttitle = {File},
  year = {1913},
  month = jan,
  journal = {Wikipedia},
  urldate = {2024-03-19},
  howpublished = {https://commons.wikimedia.org/wiki/File:Youngronaldfisher2.JPG},
  langid = {english},
  file = {/Users/javiermtz/Zotero/storage/R3IXSBSL/FileYoungronaldfisher2.html}
}

@article{Nuzzo:2014,
  title = {Scientific Method: {{Statistical}} Errors},
  shorttitle = {Scientific Method},
  author = {Nuzzo, Regina},
  year = {2014},
  month = feb,
  journal = {Nature},
  volume = {506},
  number = {7487},
  pages = {150--152},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/506150a},
  urldate = {2024-03-19},
  abstract = {P values, the 'gold standard' of statistical validity, are not as reliable as many scientists assume.},
  copyright = {2014 Springer Nature Limited},
  langid = {english},
  keywords = {Lab life,Mathematics and computing,Medical research,Publishing},
  file = {/Users/javiermtz/Zotero/storage/7PNWBME6/506150a.html}
}

@article{Oscbtec:2019,
  title = {Open Science Challenges, Benefits and Tips in Early Career and Beyond},
  year = {2019},
  month = may,
  journal = {PLOS Biology},
  volume = {17},
  number = {5},
  pages = {e3000246},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3000246},
  urldate = {2024-03-19},
  abstract = {The movement towards open science is a consequence of seemingly pervasive failures to replicate previous research. This transition comes with great benefits but also significant challenges that are likely to affect those who carry out the research, usually early career researchers (ECRs). Here, we describe key benefits, including reputational gains, increased chances of publication, and a broader increase in the reliability of research. The increased chances of publication are supported by exploratory analyses indicating null findings are substantially more likely to be published via open registered reports in comparison to more conventional methods. These benefits are balanced by challenges that we have encountered and that involve increased costs in terms of flexibility, time, and issues with the current incentive structure, all of which seem to affect ECRs acutely. Although there are major obstacles to the early adoption of open science, overall open science practices should benefit both the ECR and improve the quality of research. We review 3 benefits and 3 challenges and provide suggestions from the perspective of ECRs for moving towards open science practices, which we believe scientists and institutions at all levels would do well to consider.},
  langid = {english}
}

@misc{P:2024,
  title = {P-{{Values}}},
  journal = {xkcd},
  urldate = {2024-03-15},
  howpublished = {https://xkcd.com/1478/},
  file = {/Users/javiermtz/Zotero/storage/WYU44NEP/1478.html}
}

@misc{Resnick:2017,
  title = {What a Nerdy Debate about P-Values Shows about Science --- and How to Fix It},
  author = {Resnick, Brian},
  year = {2017},
  month = jul,
  journal = {Vox},
  urldate = {2024-03-19},
  abstract = {The case for, and against, redefining "statistical significance."},
  howpublished = {https://www.vox.com/science-and-health/2017/7/31/16021654/p-values-statistical-significance-redefine-0005},
  langid = {english},
  file = {/Users/javiermtz/Zotero/storage/CPL6FKRS/p-values-statistical-significance-redefine-0005.html}
}

@misc{S:2024,
  title = {Significant},
  journal = {xkcd},
  urldate = {2024-03-15},
  howpublished = {https://xkcd.com/882/},
  file = {/Users/javiermtz/Zotero/storage/YPDN2T3E/882.html}
}

@misc{Simonsohn:2020,
  title = {[91] p-Hacking Fast and Slow: {{Evaluating}} a Forthcoming {{AER}} Paper Deeming Some Econ Literatures Less Trustworthy},
  shorttitle = {[91] p-Hacking Fast and Slow},
  author = {Simonsohn, Uri},
  year = {2020},
  month = sep,
  journal = {Data Colada},
  urldate = {2024-03-19},
  abstract = {The authors of a forthcoming AER article (.pdf), "Methods Matter: P-Hacking and Publication Bias in Causal Analysis in Economics", painstakingly harvested thousands of test results from 25 economics journals to answer an interesting question: Are studies that use some research designs more trustworthy than others? In this post I will explain why I think their...},
  howpublished = {https://datacolada.org/91},
  langid = {american},
  file = {/Users/javiermtz/Zotero/storage/QWLWAM79/91.html}
}

@article{WassersteinLazar:2016,
  title = {The {{ASA Statement}} on P-{{Values}}: {{Context}}, {{Process}}, and {{Purpose}}},
  shorttitle = {The {{ASA Statement}} on P-{{Values}}},
  author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
  year = {2016},
  month = apr,
  journal = {The American Statistician},
  volume = {70},
  number = {2},
  pages = {129--133},
  publisher = {Taylor \& Francis},
  issn = {0003-1305},
  doi = {10.1080/00031305.2016.1154108},
  urldate = {2024-03-19}
}
